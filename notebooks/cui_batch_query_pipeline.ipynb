{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### INSTALL PACKAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#install to get latest version\n",
    "# !pip install git+https://github.com/kevon217/data-dictionary-cui-mapping.git\n",
    "# !pip install data-dictionary-cui-mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP-1A: RUN BATCH QUERY PIPELINE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### IMPORT PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T13:43:46.537020600Z",
     "start_time": "2023-07-16T13:43:46.514333700Z"
    }
   },
   "outputs": [],
   "source": [
    "from ddcuimap.umls import batch_query_pipeline as umls_bqp\n",
    "from ddcuimap.metamap import batch_query_pipeline as mm_bqp\n",
    "from ddcuimap.semantic_search import batch_hybrid_query_pipeline as ss_bqp\n",
    "from ddcuimap.hydra_search import batch_hydra_query_pipeline as hs_bqp\n",
    "\n",
    "from ddcuimap.utils import helper\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### LOAD/EDIT CONFIGURATION FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-07-16T13:36:59.984235400Z",
     "start_time": "2023-07-16T13:36:58.943834400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apis:\n",
      "  pinecone:\n",
      "    index_info:\n",
      "      apiKey: null\n",
      "      environment: null\n",
      "custom:\n",
      "  settings:\n",
      "    custom_config: title_def\n",
      "    pipeline_name: null\n",
      "  data_dictionary_settings:\n",
      "    filepath: null\n",
      "    variable_column: variable name\n",
      "    query_term_columns:\n",
      "    - title\n",
      "    - definition\n",
      "    explode: false\n",
      "    column_sep: null\n",
      "    search_all_query_terms: false\n",
      "  preprocessing_settings:\n",
      "    remove_stopwords: false\n",
      "    stopwords_filepath: null\n",
      "    use_cheatsheet: false\n",
      "    cheatsheet_filepath: null\n",
      "  curation_settings:\n",
      "    information_columns:\n",
      "    - variable name\n",
      "    - title\n",
      "    - definition\n",
      "    - permissible values\n",
      "    - permissible value descriptions\n",
      "    - preferred question text\n",
      "    query_columns:\n",
      "    - variable name\n",
      "    - search_ID\n",
      "    - query_term_used\n",
      "    - query_term_used_col\n",
      "    - searchType\n",
      "    result_columns:\n",
      "    - recCount\n",
      "    - data element concept names\n",
      "    - data element concept identifiers\n",
      "    - data element terminology sources\n",
      "    file_settings:\n",
      "      directory_prefix: DE\n",
      "      file_prefix: DE\n",
      "      excel:\n",
      "        sheet_names:\n",
      "          sheet1: UMLS_curation\n",
      "          sheet2: Data_Dictionary\n",
      "          sheet3: Data_Dictionary_extracted\n",
      "        hide_cols_curation: null\n",
      "        order_cols_curation: null\n",
      "  create_dictionary_import_settings:\n",
      "    curation_file_path: null\n",
      "    umls_columns:\n",
      "    - data element concept names\n",
      "    - data element concept identifiers\n",
      "    - data element terminology sources\n",
      "    join_on:\n",
      "    - variable name\n",
      "    - title_extracted\n",
      "    cui_sep: '|'\n",
      "    multi_cui_sep: /\n",
      "    override:\n",
      "      sep: '|'\n",
      "      columns:\n",
      "      - data element terminology sources\n",
      "      value: UMLS\n",
      "    dict_file_path: null\n",
      "    dict_file_type: csv\n",
      "    dictionary_columns:\n",
      "    - variable name\n",
      "    - title\n",
      "    - element type\n",
      "    - definition\n",
      "    - short description\n",
      "    - datatype\n",
      "    - maximum character quantity\n",
      "    - input restriction\n",
      "    - minimum value\n",
      "    - maximum value\n",
      "    - data element concept names\n",
      "    - data element concept identifiers\n",
      "    - data element terminology sources\n",
      "    - permissible values\n",
      "    - permissible value descriptions\n",
      "    - permissible value output codes\n",
      "    - permissible value concept names\n",
      "    - permissible value concept identifiers\n",
      "    - permissible value terminology sources\n",
      "    - unit of measure\n",
      "    - guidelines/instructions\n",
      "    - notes\n",
      "    - preferred question text\n",
      "    - keywords\n",
      "    - references\n",
      "    - historical notes\n",
      "    - see also\n",
      "    - effective date\n",
      "    - until date\n",
      "    - population.all\n",
      "    - domain.general (for all diseases)\n",
      "    - domain.traumatic brain injury\n",
      "    - domain.Parkinson's disease\n",
      "    - domain.Friedreich's ataxia\n",
      "    - domain.stroke\n",
      "    - domain.amyotrophic lateral sclerosis\n",
      "    - domain.Huntington's disease\n",
      "    - domain.multiple sclerosis\n",
      "    - domain.neuromuscular diseases\n",
      "    - domain.myasthenia gravis\n",
      "    - domain.spinal muscular atrophy\n",
      "    - domain.Duchenne muscular dystrophy/Becker muscular dystrophy\n",
      "    - domain.congenital muscular dystrophy\n",
      "    - domain.spinal cord injury\n",
      "    - domain.headache\n",
      "    - domain.epilepsy\n",
      "    - classification.general (for all diseases)\n",
      "    - classification.acute hospitalized\n",
      "    - classification.concussion/mild TBI\n",
      "    - classification.epidemiology\n",
      "    - 'classification.moderate/severe TBI: rehabilitation'\n",
      "    - classification.Parkinson's disease\n",
      "    - classification.Friedreich's ataxia\n",
      "    - classification.stroke\n",
      "    - classification.amyotrophic lateral sclerosis\n",
      "    - classification.Huntington's disease\n",
      "    - classification.multiple sclerosis\n",
      "    - classification.neuromuscular diseases\n",
      "    - classification.myasthenia gravis\n",
      "    - classification.spinal muscular atrophy\n",
      "    - classification.Duchenne muscular dystrophy/Becker muscular dystrophy\n",
      "    - classification.congenital muscular dystrophy\n",
      "    - classification.spinal cord injury\n",
      "    - classification.headache\n",
      "    - classification.epilepsy\n",
      "    - Label(s)\n",
      "    - submitting organization name\n",
      "    - submitting contact name\n",
      "    - submitting contact information\n",
      "    - steward organization name\n",
      "    - steward contact name\n",
      "    - steward contact information\n",
      "    check_cuis:\n",
      "      de:\n",
      "        reference_column: variable name\n",
      "        check_columns:\n",
      "        - data element concept names\n",
      "        - data element concept identifiers\n",
      "        - data element terminology sources\n",
      "      pvd:\n",
      "        reference_column: permissible value descriptions\n",
      "        check_columns:\n",
      "        - permissible value concept names\n",
      "        - permissible value concept identifiers\n",
      "        - permissible value terminology sources\n",
      "semantic_search:\n",
      "  semantic_search_settings:\n",
      "    device: cpu\n",
      "    parent_dir: null\n",
      "  umls_subset:\n",
      "    settings:\n",
      "      dirpath_output: C:\\Users\\armengolkm\\Desktop\\Full Pipeline Test v1.1.0\\UMLS_subset\\raw\n",
      "    mth_local:\n",
      "      dirpath_mth: C:\\Users\\armengolkm\\Documents\\BRICS\\Data_Elements_Form_Structures\\UMLS\\umls-2022AB-full\\2022AB-full\\2022AB\\META\n",
      "      RRF_files:\n",
      "        concepts:\n",
      "          filename: MRCONSO.RRF\n",
      "          columns:\n",
      "          - CUI\n",
      "          - LAT\n",
      "          - TS\n",
      "          - LUI\n",
      "          - STT\n",
      "          - SUI\n",
      "          - ISPREF\n",
      "          - AUI\n",
      "          - SAUI\n",
      "          - SCUI\n",
      "          - SDUI\n",
      "          - SAB\n",
      "          - TTY\n",
      "          - CODE\n",
      "          - STR\n",
      "          - SRL\n",
      "          - SUPPRESS\n",
      "          - CVF\n",
      "          - ''\n",
      "          subset:\n",
      "          - CUI\n",
      "          - SAB\n",
      "          - STR\n",
      "          - TTY\n",
      "        definitions:\n",
      "          filename: MRDEF.RRF\n",
      "          columns:\n",
      "          - CUI\n",
      "          - AUI\n",
      "          - ATUI\n",
      "          - SATUI\n",
      "          - SAB\n",
      "          - DEF\n",
      "          - SUPPRESS\n",
      "          - CVF\n",
      "          - ''\n",
      "          subset:\n",
      "          - CUI\n",
      "          - SAB\n",
      "          - DEF\n",
      "        semantic_types:\n",
      "          filename: MRSTY.RRF\n",
      "          columns:\n",
      "          - CUI\n",
      "          - TUI\n",
      "          - STN\n",
      "          - STY\n",
      "          - ATUI\n",
      "          - CVF\n",
      "          - ''\n",
      "          subset:\n",
      "          - CUI\n",
      "          - STY\n",
      "        termtype_rank:\n",
      "          filename: MRRANK.RRF\n",
      "          columns:\n",
      "          - index\n",
      "          - TUI\n",
      "          - TTY\n",
      "          - SUPPRESS\n",
      "          - empty\n",
      "          subset:\n",
      "          - TUI\n",
      "          - TTY\n",
      "    filters:\n",
      "      LAT:\n",
      "      - ENG\n",
      "  pinecone:\n",
      "    index:\n",
      "      index_name: umls-cui-hybrid-semantic-search\n",
      "      dimension: 768\n",
      "      metric: dotproduct\n",
      "      pod_type: p1\n",
      "      namespaces:\n",
      "      - STR\n",
      "      - DEF\n",
      "  upsert:\n",
      "    filepath_raw: C:/Users/armengolkm/Desktop/Full Pipeline Test v1.1.0/UMLS_subset/raw/df_umls.pkl\n",
      "    filepath_processed: C:/Users/armengolkm/Desktop/Full Pipeline Test v1.1.0/UMLS_subset/processed/df_umls_embeddings.pkl\n",
      "    filepath_dict_upsert_ids: C:/Users/armengolkm/Desktop/Full Pipeline Test v1.1.0/UMLS_subset/processed/dict_umls_upsert_ids.pkl\n",
      "    embed:\n",
      "      dense:\n",
      "        model_name: pritamdeka/PubMedBERT-mnli-snli-scinli-scitail-mednli-stsb\n",
      "        normalize: true\n",
      "      sparse:\n",
      "        model_name: naver/splade-cocondenser-ensembledistil\n",
      "        batch_size: 100\n",
      "        normalize: true\n",
      "    embed_columns:\n",
      "    - STR\n",
      "    - DEF\n",
      "    metadata:\n",
      "      tokenize_embed_columns: true\n",
      "      tokenizer:\n",
      "        model_name: transfo-xl-wt103\n",
      "      tokenize_columns:\n",
      "      - STR\n",
      "      - DEF\n",
      "      include_columns:\n",
      "      - CUI\n",
      "      - STR\n",
      "      - STY\n",
      "      - SAB_MRDEF\n",
      "      - SAB_CUI_DEF_all\n",
      "      - SAB_MRCONSO\n",
      "      - SAB_CUI_CONSO_all\n",
      "  query:\n",
      "    filepath_embeddings: null\n",
      "    filepath_results: null\n",
      "    embed:\n",
      "      dense:\n",
      "        model_name: pritamdeka/PubMedBERT-mnli-snli-scinli-scitail-mednli-stsb\n",
      "        normalize: true\n",
      "      sparse:\n",
      "        model_name: naver/splade-cocondenser-ensembledistil\n",
      "        batch_size: 100\n",
      "        normalize: true\n",
      "    embed_columns:\n",
      "    - title_extracted\n",
      "    - definition_extracted\n",
      "    metadata:\n",
      "      tokenize_embed_columns: true\n",
      "      tokenizer:\n",
      "        model_name: transfo-xl-wt103\n",
      "      tokenize_columns:\n",
      "      - title_extracted\n",
      "      - definition_extracted\n",
      "      include_columns:\n",
      "      - preferred question text\n",
      "    alpha:\n",
      "    - 1.0\n",
      "    - 0.5\n",
      "    - 0.0\n",
      "    namespace:\n",
      "    - STR\n",
      "    - DEF\n",
      "    top_k: 10\n",
      "    queries:\n",
      "      dense:\n",
      "        title_str:\n",
      "        - title_extracted_dense_vecs\n",
      "        - STR\n",
      "        definition_def:\n",
      "        - definition_extracted_dense_vecs\n",
      "        - DEF\n",
      "      hybrid:\n",
      "        title_str:\n",
      "        - title_extracted\n",
      "        - STR\n",
      "        definition_def:\n",
      "        - definition_extracted\n",
      "        - DEF\n",
      "curation:\n",
      "  langchain:\n",
      "    openai:\n",
      "      model_name: text-davinci-003\n",
      "      temperature: 0.0\n",
      "      encoding_name: p50k_base\n",
      "      pricing_model: davinci\n",
      "  preprocessing:\n",
      "    variable_column: variable name\n",
      "    overall_rank: 5\n",
      "    top_k_score: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg_hydra = helper.compose_config(overrides=[\"custom=hydra_base\"])\n",
    "# cfg_umls = helper.compose_config(overrides=[\"custom=de\", \"apis=config_umls_api\"])\n",
    "cfg_mm = helper.compose_config(overrides=[\"custom=de\", \"apis=config_metamap_api\"])\n",
    "cfg_ss = helper.compose_config(\n",
    "    overrides=[\n",
    "        \"custom=title_def\",\n",
    "        \"semantic_search=embeddings\",\n",
    "        \"apis=config_pinecone_api\",\n",
    "        \"curation=chain_setup\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# # UMLS API CREDENTIALS\n",
    "# cfg_umls.apis.umls.user_info.apiKey = ''\n",
    "# cfg_umls.apis.umls.user_info.email = ''\n",
    "\n",
    "# # MetaMap API CREDENTIALS\n",
    "# cfg_mm.apis.metamap.user_info.apiKey = ''\n",
    "# cfg_mm.apis.metamap.user_info.email = ''\n",
    "#\n",
    "# # Pinecone API CREDENTIALS\n",
    "# cfg_ss.apis.pinecone.index_info.apiKey = ''\n",
    "# cfg_ss.apis.pinecone.index_info.environment = ''\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg_ss))\n",
    "# print(OmegaConf.to_yaml(cfg_hydra))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### RUN BATCH QUERY PIPELINE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-07-16T13:38:32.472077700Z",
     "start_time": "2023-07-16T13:37:01.041973700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[37m2023-07-16 09:37:01\u001B[0m - \u001B[37msemantic_search_logger\u001B[0m - \u001B[1;37mWARNING\u001B[0m - \u001B[93mNo apiKey found in config files. Looking in .env file.\u001B[0m\n",
      "\u001B[37m2023-07-16 09:37:01\u001B[0m - \u001B[37msemantic_search_logger\u001B[0m - \u001B[1;37mINFO\u001B[0m - \u001B[32mUsing API_KEY_PINECONE found in .env file.\u001B[0m\n",
      "\u001B[37m2023-07-16 09:37:01\u001B[0m - \u001B[37msemantic_search_logger\u001B[0m - \u001B[1;37mWARNING\u001B[0m - \u001B[93mNo environment found in config files. Looking in .env file.\u001B[0m\n",
      "\u001B[37m2023-07-16 09:37:01\u001B[0m - \u001B[37msemantic_search_logger\u001B[0m - \u001B[1;37mINFO\u001B[0m - \u001B[32mUsing API_KEY_PINECONE found in .env file.\u001B[0m\n",
      "\u001B[37m2023-07-16 09:37:02\u001B[0m - \u001B[37msemantic_search_logger\u001B[0m - \u001B[1;37mINFO\u001B[0m - \u001B[32mPinecone indexes available: ['umls-cui-hybrid-semantic-search']\u001B[0m\n",
      "\u001B[37m2023-07-16 09:37:02\u001B[0m - \u001B[37msemantic_search_logger\u001B[0m - \u001B[1;37mINFO\u001B[0m - \u001B[32mStats for index 'umls-cui-hybrid-semantic-search': {'dimension': 768,\n",
      " 'index_fullness': 0.7,\n",
      " 'namespaces': {'DEF': {'vector_count': 259368},\n",
      "                'STR': {'vector_count': 259368},\n",
      "                'definition': {'vector_count': 9390},\n",
      "                'title': {'vector_count': 9390}},\n",
      " 'total_vector_count': 537516}\u001B[0m\n",
      "\u001B[37m2023-07-16 09:37:39\u001B[0m - \u001B[37mhelper_logger\u001B[0m - \u001B[1;37mINFO\u001B[0m - \u001B[32mFile chosen: C:/Users/armengolkm/Desktop/Full Pipeline Test v1.1.0/Curation_Testing/test2/FITBIR_cuis_20-DEs.csv\u001B[0m\n",
      "\u001B[37m2023-07-16 09:37:39\u001B[0m - \u001B[37mcuration_logger\u001B[0m - \u001B[1;37mINFO\u001B[0m - \u001B[32mData Dictionary shape is: (20, 80)\u001B[0m\n",
      "\u001B[37m2023-07-16 09:37:39\u001B[0m - \u001B[37mhelper_logger\u001B[0m - \u001B[1;37mINFO\u001B[0m - \u001B[32mFolder created: C:\\Users\\armengolkm\\Desktop\\Full Pipeline Test v1.1.0\\Curation_Testing\\test2\\DE_Step-1_hybrid-semantic-search\u001B[0m\n",
      "\u001B[37m2023-07-16 09:37:39\u001B[0m - \u001B[37mcuration_logger\u001B[0m - \u001B[1;37mWARNING\u001B[0m - \u001B[93mCheatsheet not used\u001B[0m\n",
      "\u001B[37m2023-07-16 09:37:39\u001B[0m - \u001B[37mcuration_logger\u001B[0m - \u001B[1;37mINFO\u001B[0m - \u001B[32mProcessed Data Dictionary shape is: (20, 86)\u001B[0m\n",
      "\u001B[37m2023-07-16 09:37:39\u001B[0m - \u001B[37msemantic_search_logger\u001B[0m - \u001B[1;37mINFO\u001B[0m - \u001B[32mRunning on cpu\u001B[0m\n",
      "\u001B[37m2023-07-16 09:37:44\u001B[0m - \u001B[37msemantic_search_logger\u001B[0m - \u001B[1;37mINFO\u001B[0m - \u001B[32mEmbedding title_extracted\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9632676ee15b45dd89b48086b5637dee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[37m2023-07-16 09:37:45\u001B[0m - \u001B[37msemantic_search_logger\u001B[0m - \u001B[1;37mINFO\u001B[0m - \u001B[32mEmbedding 0 to 100\u001B[0m\n",
      "C:\\Users\\armengolkm\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\data-dictionary-cui-mapping-U7yrxD7_-py3.9\\lib\\site-packages\\torch\\amp\\autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "\u001B[37m2023-07-16 09:37:46\u001B[0m - \u001B[37msemantic_search_logger\u001B[0m - \u001B[1;37mINFO\u001B[0m - \u001B[32mEmbedding definition_extracted\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8455f7f5d14c45bbb14c4ddba9edce51"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[37m2023-07-16 09:37:48\u001B[0m - \u001B[37msemantic_search_logger\u001B[0m - \u001B[1;37mINFO\u001B[0m - \u001B[32mEmbedding 0 to 100\u001B[0m\n",
      "C:\\Users\\armengolkm\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\data-dictionary-cui-mapping-U7yrxD7_-py3.9\\lib\\site-packages\\torch\\amp\\autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "\u001B[37m2023-07-16 09:37:52\u001B[0m - \u001B[37msemantic_search_logger\u001B[0m - \u001B[1;37mINFO\u001B[0m - \u001B[32mTokenizing title_extracted\u001B[0m\n",
      "\u001B[37m2023-07-16 09:37:52\u001B[0m - \u001B[37msemantic_search_logger\u001B[0m - \u001B[1;37mINFO\u001B[0m - \u001B[32mTokenizing definition_extracted\u001B[0m\n",
      "Semantic Search Runner: 100%|██████████| 20/20 [00:07<00:00,  2.73it/s]\n",
      "Aggregating Results: 100%|██████████| 20/20 [00:00<00:00, 152.05it/s]\n",
      "Semantic Search Runner: 100%|██████████| 20/20 [00:07<00:00,  2.78it/s]\n",
      "Aggregating Results: 100%|██████████| 20/20 [00:00<00:00, 102.71it/s]\n",
      "Semantic Search Runner: 100%|██████████| 20/20 [00:06<00:00,  3.05it/s]\n",
      "Aggregating Results: 100%|██████████| 20/20 [00:00<00:00, 108.50it/s]\n",
      "\u001B[37m2023-07-16 09:38:32\u001B[0m - \u001B[37msemantic_search_logger\u001B[0m - \u001B[1;37mINFO\u001B[0m - \u001B[32mFINISHED Pinecone Semantic Search batch query pipeline!!!\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        variable name                                      pipeline_name  \\\n",
      "0  GOSELvlRestrictInd  hybrid_semantic_search (custom=title_def, alph...   \n",
      "1  GOSELvlRestrictInd  hybrid_semantic_search (custom=title_def, alph...   \n",
      "2  GOSELvlRestrictInd  hybrid_semantic_search (custom=title_def, alph...   \n",
      "3  GOSELvlRestrictInd  hybrid_semantic_search (custom=title_def, alph...   \n",
      "4  GOSELvlRestrictInd  hybrid_semantic_search (custom=title_def, alph...   \n",
      "\n",
      "   search_ID                                              title  \\\n",
      "0          1  Glasgow Outcome Scale Extended (GOS-E) - Work ...   \n",
      "1          1  Glasgow Outcome Scale Extended (GOS-E) - Work ...   \n",
      "2          1  Glasgow Outcome Scale Extended (GOS-E) - Work ...   \n",
      "3          1  Glasgow Outcome Scale Extended (GOS-E) - Work ...   \n",
      "4          1  Glasgow Outcome Scale Extended (GOS-E) - Work ...   \n",
      "\n",
      "                                          definition permissible values  \\\n",
      "0  Indicator if the participant was either workin...             No|Yes   \n",
      "1  Indicator if the participant was either workin...             No|Yes   \n",
      "2  Indicator if the participant was either workin...             No|Yes   \n",
      "3  Indicator if the participant was either workin...             No|Yes   \n",
      "4  Indicator if the participant was either workin...             No|Yes   \n",
      "\n",
      "  permissible value descriptions  \\\n",
      "0                         No|Yes   \n",
      "1                         No|Yes   \n",
      "2                         No|Yes   \n",
      "3                         No|Yes   \n",
      "4                         No|Yes   \n",
      "\n",
      "                             preferred question text  \\\n",
      "0  Work:  Were they either working or seeking emp...   \n",
      "1  Work:  Were they either working or seeking emp...   \n",
      "2  Work:  Were they either working or seeking emp...   \n",
      "3  Work:  Were they either working or seeking emp...   \n",
      "4  Work:  Were they either working or seeking emp...   \n",
      "\n",
      "                                     title_extracted  \\\n",
      "0  Glasgow Outcome Scale Extended  GOS E    Work ...   \n",
      "1  Glasgow Outcome Scale Extended  GOS E    Work ...   \n",
      "2  Glasgow Outcome Scale Extended  GOS E    Work ...   \n",
      "3  Glasgow Outcome Scale Extended  GOS E    Work ...   \n",
      "4  Glasgow Outcome Scale Extended  GOS E    Work ...   \n",
      "\n",
      "                                definition_extracted  ...  \\\n",
      "0  Indicator if the participant was either workin...  ...   \n",
      "1  Indicator if the participant was either workin...  ...   \n",
      "2  Indicator if the participant was either workin...  ...   \n",
      "3  Indicator if the participant was either workin...  ...   \n",
      "4  Indicator if the participant was either workin...  ...   \n",
      "\n",
      "  data element terminology sources definition_source overall_count  \\\n",
      "0                              NCI               NCI             2   \n",
      "1                              NCI               NCI             1   \n",
      "2                              NCI               NCI             1   \n",
      "3                              NCI               NCI             1   \n",
      "4                              NCI               NCI             1   \n",
      "\n",
      "  average_score overall_rank title_str_rank title_str_score  \\\n",
      "0         0.697            1              1        0.534068   \n",
      "1         0.647            2              0             NaN   \n",
      "2         0.619            3              0             NaN   \n",
      "3         0.617            4              0             NaN   \n",
      "4         0.612            5              0             NaN   \n",
      "\n",
      "  definition_def_rank definition_def_score keep  \n",
      "0                   1             0.859169  NaN  \n",
      "1                   2             0.647044  NaN  \n",
      "2                   3             0.619232  NaN  \n",
      "3                   4             0.616826  NaN  \n",
      "4                   5             0.611793  NaN  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "# df_umls, cfg_umls = umls_bqp.run_umls_batch(cfg_umls)\n",
    "# df_mm, cfg_mm = mm_bqp.run_mm_batch(cfg_mm)\n",
    "df_ss, cfg_ss = ss_bqp.run_hybrid_ss_batch(cfg_ss)\n",
    "# df_hydra, cfg_step1 = hs_bqp.run_hydra_batch(cfg_hydra, cfg_umls=None, cfg_mm=cfg_mm, cfg_ss=cfg_ss)\n",
    "\n",
    "print(df_ss.head())\n",
    "# print(df_hydra.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP-1B: *MANUAL CURATION STEP IN EXCEL\n",
    "*see curation example in ***notebooks/examples_files/DE_Step-1_curation_keepCol.xlsx***"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP-1B: *LLM CURATION WITH SEMANTIC SEARCH RESULTS\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df_ss.shape)\n",
    "df_ss.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'langchain': {'openai': {'model_name': 'gpt-3.5-turbo', 'temperature': 0.0, 'encoding_name': 'cl100k_base', 'pricing_model': 'gpt-3.5-turbo'}}, 'preprocessing': {'variable_column': 'variable name', 'overall_rank': 5, 'top_k_score': 5}}\n"
     ]
    }
   ],
   "source": [
    "cfg_ss.curation.langchain.openai.model_name = 'gpt-3.5-turbo'\n",
    "cfg_ss.curation.langchain.openai.encoding_name = 'cl100k_base'\n",
    "cfg_ss.curation.langchain.openai.pricing_model = 'gpt-3.5-turbo'\n",
    "\n",
    "# cfg_ss.curation.langchain.openai.model_name = 'text-davinci-003'\n",
    "# cfg_ss.curation.langchain.openai.encoding_name = 'p50k_base'\n",
    "# cfg_ss.curation.langchain.openai.pricing_model = 'davinci'\n",
    "\n",
    "print(cfg_ss.curation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T13:43:02.090143800Z",
     "start_time": "2023-07-16T13:43:02.064479600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[37m2023-07-16 09:43:20\u001B[0m - \u001B[37mhelper_logger\u001B[0m - \u001B[1;37mINFO\u001B[0m - \u001B[32mFolder created: C:\\Users\\armengolkm\\Desktop\\Full Pipeline Test v1.1.0\\Curation_Testing\\test2\\DE_Step-1_hybrid-semantic-search\\DE_curation\u001B[0m\n",
      "C:\\Users\\armengolkm\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\data-dictionary-cui-mapping-U7yrxD7_-py3.9\\lib\\site-packages\\langchain\\llms\\openai.py:173: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "C:\\Users\\armengolkm\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\data-dictionary-cui-mapping-U7yrxD7_-py3.9\\lib\\site-packages\\langchain\\llms\\openai.py:753: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOSELvlRestrictInd\n",
      "ISIDifStayAslpMeasr\n",
      "BacterialCulSpecGrowthInd\n",
      "ImgDim5ExtentVal\n",
      "CareProvisionLevel\n",
      "AUDITMornDrnkAftDrnkFreqScore\n",
      "MilMOSOTH\n",
      "NICUStayInd\n",
      "SesPrimAdultOther\n",
      "ImgInterpolationInd\n",
      "MedctnPriorConcomDoseUo\n",
      "GOSECrrntProbInd\n",
      "POMSFatigueInertiaScore\n",
      "QoLItemCompletedCount\n",
      "PANASIrritableScale\n",
      "HeadachWorsDurngActvtyInd\n",
      "SexSubjectGenotypTyp\n",
      "POMSSFFeelFatigudScl\n",
      "ISIWakErMeasr\n",
      "ImgAnlysisSftwrVrsnNum\n",
      "# of tokens: 1062 (0.002 USD)\n",
      "# of tokens: 1068 (0.002 USD)\n",
      "# of tokens: 1023 (0.002 USD)\n",
      "# of tokens: 1062 (0.002 USD)\n",
      "# of tokens: 1268 (0.003 USD)\n",
      "# of tokens: 1146 (0.002 USD)\n",
      "# of tokens: 1009 (0.002 USD)\n",
      "# of tokens: 1000 (0.002 USD)\n",
      "# of tokens: 1054 (0.002 USD)\n",
      "# of tokens: 977 (0.002 USD)\n",
      "# of tokens: 991 (0.002 USD)\n",
      "# of tokens: 1141 (0.002 USD)\n",
      "# of tokens: 1025 (0.002 USD)\n",
      "# of tokens: 1380 (0.003 USD)\n",
      "# of tokens: 1048 (0.002 USD)\n",
      "# of tokens: 984 (0.002 USD)\n",
      "# of tokens: 1125 (0.002 USD)\n",
      "# of tokens: 1036 (0.002 USD)\n",
      "# of tokens: 1132 (0.002 USD)\n",
      "# of tokens: 975 (0.002 USD)\n",
      "Total cost of prompts: 0.042000000000000016 USD\n",
      "Tokens Used: 1236\n",
      "\tPrompt Tokens: 1069\n",
      "\tCompletion Tokens: 167\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0019375\n"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Failed to parse ConceptQA from completion {\"Answers\": {\"type\": \"object\", \"properties\": {\"1\": {\"type\": \"object\", \"properties\": {\"Reasoning\": {\"type\": \"string\", \"title\": \"Reasoning\", \"description\": \"The reason for selecting this answer\"}, \"Confidence\": {\"type\": \"integer\", \"title\": \"Confidence\", \"description\": \"Confidence score between 1-10 for this answer\"}}}, \"2\": {\"type\": \"object\", \"properties\": {\"Reasoning\": {\"type\": \"string\", \"title\": \"Reasoning\", \"description\": \"The reason for selecting this answer\"}, \"Confidence\": {\"type\": \"integer\", \"title\": \"Confidence\", \"description\": \"Confidence score between 1-10 for this answer\"}}}}}, \"required\": [\"Answers\"]}. Got: 3 validation errors for ConceptQA\nAnswers -> type\n  value is not a valid dict (type=type_error.dict)\nAnswers -> properties -> Reasoning\n  field required (type=value_error.missing)\nAnswers -> properties -> Confidence\n  field required (type=value_error.missing)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\data-dictionary-cui-mapping-U7yrxD7_-py3.9\\lib\\site-packages\\langchain\\output_parsers\\pydantic.py:26\u001B[0m, in \u001B[0;36mPydanticOutputParser.parse\u001B[1;34m(self, text)\u001B[0m\n\u001B[0;32m     25\u001B[0m     json_object \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(json_str, strict\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m---> 26\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpydantic_object\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse_obj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjson_object\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (json\u001B[38;5;241m.\u001B[39mJSONDecodeError, ValidationError) \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\data-dictionary-cui-mapping-U7yrxD7_-py3.9\\lib\\site-packages\\pydantic\\main.py:526\u001B[0m, in \u001B[0;36mpydantic.main.BaseModel.parse_obj\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\data-dictionary-cui-mapping-U7yrxD7_-py3.9\\lib\\site-packages\\pydantic\\main.py:341\u001B[0m, in \u001B[0;36mpydantic.main.BaseModel.__init__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mValidationError\u001B[0m: 3 validation errors for ConceptQA\nAnswers -> type\n  value is not a valid dict (type=type_error.dict)\nAnswers -> properties -> Reasoning\n  field required (type=value_error.missing)\nAnswers -> properties -> Confidence\n  field required (type=value_error.missing)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mOutputParserException\u001B[0m                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[38], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mddcuimap\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcuration\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mchains\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcurchain\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m run_llm_curation\n\u001B[1;32m----> 3\u001B[0m df_final, cfg_ss \u001B[38;5;241m=\u001B[39m \u001B[43mrun_llm_curation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcfg_ss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf_cur\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdf_ss\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\data-dictionary-cui-mapping\\ddcuimap\\curation\\chains\\curchain.py:119\u001B[0m, in \u001B[0;36mrun_llm_curation\u001B[1;34m(cfg, **kwargs)\u001B[0m\n\u001B[0;32m    117\u001B[0m output \u001B[38;5;241m=\u001B[39m llm(i\u001B[38;5;241m.\u001B[39mto_string())\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28mprint\u001B[39m(cb)\n\u001B[1;32m--> 119\u001B[0m answers \u001B[38;5;241m=\u001B[39m \u001B[43moutput_parser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mAnswers\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28mprint\u001B[39m(answers)\n\u001B[0;32m    121\u001B[0m outputs\u001B[38;5;241m.\u001B[39mappend(answers)\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\data-dictionary-cui-mapping-U7yrxD7_-py3.9\\lib\\site-packages\\langchain\\output_parsers\\pydantic.py:31\u001B[0m, in \u001B[0;36mPydanticOutputParser.parse\u001B[1;34m(self, text)\u001B[0m\n\u001B[0;32m     29\u001B[0m name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpydantic_object\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n\u001B[0;32m     30\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to parse \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m from completion \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtext\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Got: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 31\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m OutputParserException(msg, llm_output\u001B[38;5;241m=\u001B[39mtext)\n",
      "\u001B[1;31mOutputParserException\u001B[0m: Failed to parse ConceptQA from completion {\"Answers\": {\"type\": \"object\", \"properties\": {\"1\": {\"type\": \"object\", \"properties\": {\"Reasoning\": {\"type\": \"string\", \"title\": \"Reasoning\", \"description\": \"The reason for selecting this answer\"}, \"Confidence\": {\"type\": \"integer\", \"title\": \"Confidence\", \"description\": \"Confidence score between 1-10 for this answer\"}}}, \"2\": {\"type\": \"object\", \"properties\": {\"Reasoning\": {\"type\": \"string\", \"title\": \"Reasoning\", \"description\": \"The reason for selecting this answer\"}, \"Confidence\": {\"type\": \"integer\", \"title\": \"Confidence\", \"description\": \"Confidence score between 1-10 for this answer\"}}}}}, \"required\": [\"Answers\"]}. Got: 3 validation errors for ConceptQA\nAnswers -> type\n  value is not a valid dict (type=type_error.dict)\nAnswers -> properties -> Reasoning\n  field required (type=value_error.missing)\nAnswers -> properties -> Confidence\n  field required (type=value_error.missing)"
     ]
    }
   ],
   "source": [
    "from ddcuimap.curation.chains.curchain import run_llm_curation\n",
    "\n",
    "df_final, cfg_ss = run_llm_curation(cfg_ss, df_cur=df_ss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T13:43:26.628179500Z",
     "start_time": "2023-07-16T13:43:20.764601100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP-2A: CREATE DATA DICTIONARY IMPORT FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### IMPORT CURATION PACKAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ddcuimap.curation import create_dictionary_import_file\n",
    "from ddcuimap.curation import check_cuis\n",
    "from ddcuimap.utils import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### CREATE DATA DICTIONARY IMPORT FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg_step1 = helper.load_config(helper.choose_file(\"Load config file from Step 1\"))\n",
    "df_dd = create_dictionary_import_file.create_dd_file(cfg_step1)\n",
    "print(df_dd.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP-2B: CHECK CUIS IN DATA DICTIONARY IMPORT FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_step2 = helper.load_config(helper.choose_file(\"Load config file from Step 2\"))\n",
    "df_check = check_cuis.check_cuis(cfg_step2)\n",
    "print(df_check.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
